from pathlib import Path
import hashlib
import json
import base64
import asyncio
import os
import time
from utils.platform_config import IS_MACOS, IS_WINDOWS
from utils.message_format import ClipMessage, MessageType
from config import ClipboardConfig

# Only import AppKit and objc on macOS
if IS_MACOS:
    import AppKit
    import objc # Import objc

    # Helper class to perform pasteboard operations on the main thread
    class PasteboardSetter(AppKit.NSObject):
        @classmethod # Use standard Python classmethod decorator
        def setFileURL_(cls, path_str):
            try:
                pasteboard = AppKit.NSPasteboard.generalPasteboard()
                pasteboard.clearContents()
                url = AppKit.NSURL.fileURLWithPath_(path_str)
                if not url:
                    print(f"âŒ [MainThread] æ— æ³•åˆ›å»ºæ–‡ä»¶URL: {path_str}")
                    return "0|-1"
                urls = AppKit.NSArray.arrayWithObject_(url)
                success = pasteboard.writeObjects_(urls)
                if success:
                    change_count = pasteboard.changeCount()
                    print(f"ğŸ“ [MainThread] å·²å°†æ–‡ä»¶æ·»åŠ åˆ°Macå‰ªè´´æ¿: {Path(path_str).name}")
                    return f"1|{change_count}"
                else:
                    print(f"âŒ [MainThread] æ·»åŠ æ–‡ä»¶åˆ°Macå‰ªè´´æ¿å¤±è´¥: {Path(path_str).name}")
                    return "0|-1"
            except Exception as e:
                print(f"âŒ [MainThread] è®¾ç½®å‰ªè´´æ¿æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                return "0|-1"


class FileHandler:
    """æ–‡ä»¶å¤„ç†ç®¡ç†å™¨"""
    
    def __init__(self, temp_dir: Path, security_mgr):
        self.temp_dir = temp_dir
        self.security_mgr = security_mgr
        self.file_transfers = {}
        self.file_cache = {}
        self._init_temp_dir()
        self.load_file_cache()
        self.chunk_size = ClipboardConfig.CHUNK_SIZE # Use config
        self.pending_transfers = {}  # Track ongoing chunked transfers

    def _init_temp_dir(self):
        """åˆå§‹åŒ–ä¸´æ—¶ç›®å½•"""
        self.temp_dir.mkdir(exist_ok=True)
        print(f"âœ… æ–‡ä»¶å¤„ç†åˆå§‹åŒ–æˆåŠŸï¼Œä¸´æ—¶ç›®å½•: {self.temp_dir}")

    def _looks_like_temp_file_path(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦çœ‹èµ·æ¥åƒä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        for indicator in ClipboardConfig.TEMP_PATH_INDICATORS:
            if indicator in text:
                print(f"â­ï¸ è·³è¿‡ä¸´æ—¶æ–‡ä»¶è·¯å¾„: \"{text[:40]}...\"")
                return True
        return False

    async def handle_file_transfer(self, file_path: str, send_encrypted_fn):
        """å¤„ç†æ–‡ä»¶ä¼ è¾“ï¼ˆè‡ªåŠ¨åˆ†å—å¤§æ–‡ä»¶ï¼‰"""
        path_obj = Path(file_path)
        MAX_CHUNK_SIZE = self.chunk_size # Use instance chunk size

        if not path_obj.exists() or not path_obj.is_file():
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ•ˆ: {file_path}")
            return False

        try:
            file_size = path_obj.stat().st_size
            total_chunks = (file_size + MAX_CHUNK_SIZE - 1) // MAX_CHUNK_SIZE
            print(f"ğŸ“¤ å¼€å§‹ä¼ è¾“æ–‡ä»¶: {path_obj.name} ({file_size/1024/1024:.1f}MB, {total_chunks}å—)")

            # å‘é€æ–‡ä»¶å¼€å§‹æ¶ˆæ¯ (optional, could be part of the first chunk)
            # Consider if a separate start message is needed or if info can be in first chunk

            # é€å—è¯»å–å¹¶å‘é€æ–‡ä»¶
            with open(path_obj, 'rb') as f:
                for chunk_index in range(total_chunks):
                    chunk_data = f.read(MAX_CHUNK_SIZE)
                    if not chunk_data:
                        break

                    chunk_msg = {
                        'type': MessageType.FILE_RESPONSE,
                        'filename': path_obj.name,
                        'exists': True,
                        'chunk_data': base64.b64encode(chunk_data).decode('utf-8'),
                        'chunk_index': chunk_index,
                        'total_chunks': total_chunks,
                        'chunk_hash': hashlib.md5(chunk_data).hexdigest(),
                        'file_hash': ClipMessage.calculate_file_hash(str(path_obj)) if chunk_index == 0 else None # Send full hash only once
                    }

                    # æ˜¾ç¤ºè¿›åº¦
                    progress = self._format_progress(chunk_index + 1, total_chunks)
                    print(f"\rğŸ“¤ ä¼ è¾“æ–‡ä»¶ {path_obj.name}: {progress}", end="", flush=True)

                    # åŠ å¯†å¹¶å‘é€å—
                    await send_encrypted_fn(json.dumps(chunk_msg).encode('utf-8'))
                    await asyncio.sleep(ClipboardConfig.NETWORK_DELAY) # Use config

            print(f"\nâœ… æ–‡ä»¶ {path_obj.name} ä¼ è¾“å®Œæˆ")
            return True

        except Exception as e:
            print(f"\nâŒ æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    # Removed _transfer_small_file as handle_file_transfer now handles chunking

    # Removed send_large_file and _send_file_chunk as handle_file_transfer covers this

    # Removed receive_file_chunk as handle_received_chunk covers this

    # Removed _complete_file_transfer as handle_received_chunk handles completion

    def _format_progress(self, current: int, total: int) -> str:
        """æ ¼å¼åŒ–è¿›åº¦æ˜¾ç¤º"""
        if total <= 0: return "[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0% (0/0)" # Avoid division by zero
        percentage = (current * 100) // total
        bar_length = 20
        filled = min(bar_length, (percentage * bar_length) // 100) # Ensure filled doesn't exceed bar_length
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        return f"[{bar}] {percentage}% ({current}/{total})"

    def handle_received_chunk(self, message: dict) -> tuple[bool, Path | None]:
        """
        å¤„ç†æ¥æ”¶åˆ°çš„æ–‡ä»¶å—.
        Returns: (is_complete, file_path_if_complete)
        """
        try:
            filename = message.get("filename", "unknown")
            chunk_index = message.get("chunk_index", 0)
            total_chunks = message.get("total_chunks", 1)
            chunk_data = base64.b64decode(message.get("chunk_data", ""))
            chunk_hash = message.get("chunk_hash")
            file_hash = message.get("file_hash") # Full file hash (sent with first chunk)

            if not chunk_data:
                print("âš ï¸ æ”¶åˆ°çš„æ–‡ä»¶å—æ•°æ®ä¸ºç©º")
                return False, None

            # éªŒè¯å—çš„å®Œæ•´æ€§
            if chunk_hash and hashlib.md5(chunk_data).hexdigest() != chunk_hash:
                print(f"âš ï¸ å— {chunk_index+1}/{total_chunks} æ ¡éªŒå¤±è´¥ for {filename}")
                # Optionally request retransmission here
                return False, None

            save_path = self.temp_dir / filename

            # Initialize transfer state if first chunk
            if filename not in self.file_transfers:
                self.file_transfers[filename] = {
                    "received_chunks": {}, # Store data by index
                    "total_chunks": total_chunks,
                    "path": save_path,
                    "file_hash": file_hash # Store the expected full hash
                }
                # Clear any old file with the same name
                if save_path.exists():
                    try:
                        save_path.unlink()
                    except OSError as e:
                        print(f"âš ï¸ æ— æ³•åˆ é™¤æ—§æ–‡ä»¶ {save_path}: {e}")


            transfer = self.file_transfers[filename]

            # Store chunk data if not already received
            if chunk_index not in transfer["received_chunks"]:
                 transfer["received_chunks"][chunk_index] = chunk_data
            else:
                 print(f"â„¹ï¸ æ”¶åˆ°é‡å¤å— {chunk_index+1}/{total_chunks} for {filename}")


            # Display progress
            progress = self._format_progress(len(transfer["received_chunks"]), transfer["total_chunks"])
            print(f"\rğŸ“¥ æ¥æ”¶æ–‡ä»¶ {filename}: {progress}", end="", flush=True)


            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            is_complete = len(transfer["received_chunks"]) == transfer["total_chunks"]

            if is_complete:
                print(f"\nâœ… æ–‡ä»¶ {filename} æ‰€æœ‰å—æ¥æ”¶å®Œæˆï¼Œå¼€å§‹ç»„è£…...")
                # ç»„è£…æ–‡ä»¶
                try:
                    with open(save_path, "wb") as f:
                        for i in range(transfer["total_chunks"]):
                            if i in transfer["received_chunks"]:
                                f.write(transfer["received_chunks"][i])
                            else:
                                # This shouldn't happen if is_complete is true, but as a safeguard
                                print(f"âŒ ç»„è£…æ–‡ä»¶ {filename} æ—¶ç¼ºå°‘å— {i+1}")
                                raise IOError(f"Missing chunk {i+1} for {filename}")

                    # éªŒè¯å®Œæ•´æ–‡ä»¶å“ˆå¸Œ
                    if transfer["file_hash"]:
                        actual_hash = ClipMessage.calculate_file_hash(str(save_path))
                        if actual_hash == transfer["file_hash"]:
                            print(f"âœ… æ–‡ä»¶ {filename} å“ˆå¸Œæ ¡éªŒæˆåŠŸ")
                        else:
                            print(f"âŒ æ–‡ä»¶ {filename} å“ˆå¸Œæ ¡éªŒå¤±è´¥! Expected: {transfer['file_hash']}, Got: {actual_hash}")
                            # Optionally delete the corrupted file
                            # save_path.unlink()
                            del self.file_transfers[filename]
                            return False, None # Indicate failure
                    else:
                         print(f"âš ï¸ æœªæ”¶åˆ°æ–‡ä»¶ {filename} çš„å®Œæ•´å“ˆå¸Œå€¼ï¼Œè·³è¿‡æ ¡éªŒ")


                    # Add to cache (using the verified hash if available)
                    final_hash = transfer["file_hash"] or ClipMessage.calculate_file_hash(str(save_path))
                    self.add_to_file_cache(final_hash, str(save_path))

                    # æ¸…ç†ä¼ è¾“çŠ¶æ€
                    completed_path = transfer["path"]
                    del self.file_transfers[filename]
                    return True, completed_path # Indicate completion and return path

                except Exception as e:
                    print(f"âŒ ç»„è£…æˆ–æ ¡éªŒæ–‡ä»¶ {filename} å¤±è´¥: {e}")
                    # Clean up
                    if save_path.exists(): save_path.unlink(missing_ok=True)
                    if filename in self.file_transfers: del self.file_transfers[filename]
                    return False, None # Indicate failure

            return False, None # Indicate not yet complete

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, None # Indicate failure

    # Removed _verify_file_integrity as validation is now part of handle_received_chunk

    # --- File Cache Methods ---
    def load_file_cache(self):
        """åŠ è½½æ–‡ä»¶ç¼“å­˜"""
        cache_path = self.temp_dir / "filecache.json"
        try:
            if cache_path.exists():
                with open(cache_path, "r") as f:
                    self.file_cache = json.load(f)
                print(f"ğŸ“š å·²åŠ è½½ {len(self.file_cache)} ä¸ªæ–‡ä»¶ç¼“å­˜æ¡ç›®")
            else:
                self.file_cache = {}
                print("ğŸ“ åˆ›å»ºæ–°çš„æ–‡ä»¶ç¼“å­˜")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            self.file_cache = {}

    def save_file_cache(self):
        """ä¿å­˜æ–‡ä»¶ç¼“å­˜ä¿¡æ¯"""
        cache_path = self.temp_dir / "filecache.json"
        try:
            with open(cache_path, "w") as f:
                json.dump(self.file_cache, f)
        except Exception as e: # Catch specific exceptions if needed
            print(f"âŒ ä¿å­˜æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")

    async def handle_text_message(self, message: dict, set_clipboard_func, 
                                 last_content_hash: str) -> tuple[str, float]:
        """å¤„ç†æ¥æ”¶åˆ°çš„æ–‡æœ¬æ¶ˆæ¯"""
        try:
            text = message.get("content", "")
            if not text:
                print("âš ï¸ æ”¶åˆ°ç©ºæ–‡æœ¬æ¶ˆæ¯")
                return last_content_hash, 0
            
            if self._looks_like_temp_file_path(text):
                return last_content_hash, 0
            
            # Calculate hash before setting clipboard
            from utils.clipboard_utils import ClipboardUtils
            content_hash = ClipboardUtils.calculate_content_hash(text)
            
            # Check if duplicate
            if content_hash == last_content_hash:
                print("â­ï¸ è·³è¿‡é‡å¤å†…å®¹")
                return last_content_hash, 0
            
            # Set clipboard using provided function
            if await set_clipboard_func(text):
                display_text = ClipboardUtils.format_display_content(text)
                print(f"ğŸ“¥ å·²å¤åˆ¶æ–‡æœ¬: \"{display_text}\"")
                return content_hash, time.time()
            else:
                print("âŒ æ›´æ–°å‰ªè´´æ¿å¤±è´¥")
                return last_content_hash, 0
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡æœ¬æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            traceback.print_exc()
            return last_content_hash, 0