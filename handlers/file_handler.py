from pathlib import Path
import hashlib
import json
import base64
import asyncio
import os
import time
from utils.platform_config import IS_MACOS, IS_WINDOWS
from utils.message_format import ClipMessage, MessageType
from config import ClipboardConfig

# Only import AppKit on macOS
if IS_MACOS:
    import AppKit

class FileHandler:
    """æ–‡ä»¶å¤„ç†ç®¡ç†å™¨"""
    
    def __init__(self, temp_dir: Path, security_mgr):
        self.temp_dir = temp_dir
        self.security_mgr = security_mgr
        self.file_transfers = {}
        self.file_cache = {}
        self._init_temp_dir()
        self.load_file_cache()
        self.chunk_size = 512 * 1024  # 512KB chunks for file transfer
        self.pending_transfers = {}  # Track ongoing chunked transfers

    def _init_temp_dir(self):
        """åˆå§‹åŒ–ä¸´æ—¶ç›®å½•"""
        self.temp_dir.mkdir(exist_ok=True)
        print(f"âœ… æ–‡ä»¶å¤„ç†åˆå§‹åŒ–æˆåŠŸï¼Œä¸´æ—¶ç›®å½•: {self.temp_dir}")

    async def handle_file_transfer(self, file_path: str, broadcast_fn):
        """å¤„ç†æ–‡ä»¶ä¼ è¾“"""
        path_obj = Path(file_path)
        
        # å¢å¼ºæ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        try:
            if not path_obj.exists():
                print(f"âš ï¸ æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§: {file_path} -> ä¸å­˜åœ¨")
                abs_path = path_obj.absolute()
                print(f"ğŸ” å°è¯•ç»å¯¹è·¯å¾„: {abs_path}")
                path_obj = abs_path
                
                if not path_obj.exists():
                    print(f"âŒ æ–‡ä»¶ç¡®å®ä¸å­˜åœ¨: {file_path}")
                    return False

            print(f"âœ… æ–‡ä»¶å·²æ‰¾åˆ°: {path_obj}")
            file_size = path_obj.stat().st_size
            print(f"ğŸ“¤ å¼€å§‹å¤„ç†æ–‡ä»¶: {path_obj.name} ({file_size} å­—èŠ‚)")

            # åˆ›å»ºæ–‡ä»¶æ¶ˆæ¯
            file_msg = ClipMessage.file_message([str(path_obj)])
            message_json = ClipMessage.serialize(file_msg)
            encrypted_data = self.security_mgr.encrypt_message(
                message_json.encode('utf-8')
            )
            await broadcast_fn(encrypted_data)
            
            # è¯»å–å¹¶å‘é€æ–‡ä»¶å†…å®¹
            with open(path_obj, 'rb') as f:
                chunk_data = f.read()
                if chunk_data:
                    response = {
                        'type': MessageType.FILE_RESPONSE,
                        'filename': path_obj.name,
                        'exists': True,
                        'chunk_data': base64.b64encode(chunk_data).decode('utf-8'),
                        'chunk_index': 0,
                        'total_chunks': 1
                    }
                    
                    encrypted_resp = self.security_mgr.encrypt_message(
                        json.dumps(response).encode('utf-8')
                    )
                    await broadcast_fn(encrypted_resp)
                    print(f"ğŸ“¤ å·²å‘é€æ–‡ä»¶å†…å®¹: {path_obj.name}")
                    
                return True
                
        except Exception as e:
            print(f"âŒ æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    async def _transfer_small_file(self, path_obj: Path, file_size: int, broadcast_fn):
        """ä¼ è¾“å°æ–‡ä»¶"""
        try:
            chunk_size = 700 * 1024  # 1MB
            total_chunks = (file_size + chunk_size - 1) // chunk_size
            
            print(f"ğŸ“¤ è‡ªåŠ¨ä¼ è¾“æ–‡ä»¶: {path_obj.name} ({file_size} å­—èŠ‚, {total_chunks} å—)")
            
            with open(path_obj, 'rb') as f:
                for i in range(total_chunks):
                    chunk_data = f.read(chunk_size)
                    if not chunk_data:
                        print(f"âš ï¸ è¯»å–æ–‡ä»¶å—å¤±è´¥: {path_obj.name} å— {i+1}/{total_chunks}")
                        break
                        
                    chunk_hash = hashlib.md5(chunk_data).hexdigest()
                    
                    response = {
                        'type': MessageType.FILE_RESPONSE,
                        'filename': path_obj.name,
                        'exists': True,
                        'chunk_index': i,
                        'total_chunks': total_chunks,
                        'chunk_data': base64.b64encode(chunk_data).decode('utf-8'),
                        'chunk_hash': chunk_hash
                    }
                    
                    # åŠ å¯†å¹¶å‘é€
                    encrypted_resp = self.security_mgr.encrypt_message(
                        json.dumps(response).encode('utf-8')
                    )
                    await broadcast_fn(encrypted_resp)
                    print(f"ğŸ“¤ å·²å‘é€æ–‡ä»¶å—: {path_obj.name} ({i+1}/{total_chunks})")
                    await asyncio.sleep(0.05)  # é¿å…ç½‘ç»œæ‹¥å¡
                    
            print(f"âœ… æ–‡ä»¶ {path_obj.name} ä¼ è¾“å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    async def send_large_file(self, file_path: str, broadcast_fn):
        """åˆ†å—å‘é€å¤§æ–‡ä»¶"""
        path_obj = Path(file_path)
        if not path_obj.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False

        file_size = path_obj.stat().st_size
        total_chunks = (file_size + self.chunk_size - 1) // self.chunk_size
        file_id = hashlib.md5(f"{path_obj.name}-{time.time()}".encode()).hexdigest()

        # Send file start message
        start_message = ClipMessage.create({
            "type": MessageType.FILE_START,
            "file_id": file_id,
            "filename": path_obj.name,
            "total_chunks": total_chunks,
            "total_size": file_size
        })

        try:
            # Send start message
            encrypted_start = self.security_mgr.encrypt_message(
                ClipMessage.serialize(start_message).encode('utf-8')
            )
            await broadcast_fn(encrypted_start)
            print(f"\nğŸ“¤ å¼€å§‹å‘é€æ–‡ä»¶: {path_obj.name} ({file_size/1024/1024:.1f}MB)")

            # Send chunks
            with open(file_path, 'rb') as f:
                for i in range(total_chunks):
                    chunk = f.read(self.chunk_size)
                    await self._send_file_chunk(
                        chunk, i, file_id, path_obj.name, 
                        total_chunks, broadcast_fn
                    )
                    
                    # Show progress
                    progress = self._format_progress(i + 1, total_chunks)
                    print(f"\rğŸ“¤ å‘é€æ–‡ä»¶ {path_obj.name}: {progress}", end="")

            print(f"\nâœ… æ–‡ä»¶ {path_obj.name} å‘é€å®Œæˆ")
            return True

        except Exception as e:
            print(f"\nâŒ å‘é€æ–‡ä»¶å¤±è´¥: {e}")
            return False

    async def _send_file_chunk(self, chunk_data, chunk_number, file_id, filename, total_chunks, broadcast_fn):
        """å‘é€å•ä¸ªæ–‡ä»¶å—"""
        chunk_message = ClipMessage.create({
            "type": MessageType.FILE_CHUNK,
            "file_id": file_id,
            "chunk_number": chunk_number,
            "data": base64.b64encode(chunk_data).decode('utf-8'),
            "is_last": chunk_number == total_chunks - 1,
            "filename": filename
        })

        encrypted_chunk = self.security_mgr.encrypt_message(
            ClipMessage.serialize(chunk_message).encode('utf-8')
        )
        await broadcast_fn(encrypted_chunk)
        await asyncio.sleep(0.05)  # Prevent network congestion

    async def receive_file_chunk(self, message: dict) -> bool:
        """å¤„ç†æ¥æ”¶åˆ°çš„æ–‡ä»¶å—"""
        file_id = message.get("file_id")
        if file_id not in self.pending_transfers:
            self.pending_transfers[file_id] = {
                "chunks": {},
                "total_chunks": message.get("total_chunks", 0),
                "filename": message.get("filename", "unknown"),
                "received_chunks": 0
            }

        transfer = self.pending_transfers[file_id]
        chunk_number = message.get("chunk_number")
        chunk_data = base64.b64decode(message.get("data"))
        
        # Store chunk
        transfer["chunks"][chunk_number] = chunk_data
        transfer["received_chunks"] += 1

        # Show progress
        progress = self._format_progress(
            transfer["received_chunks"],
            transfer["total_chunks"]
        )
        print(f"\rğŸ“¥ æ¥æ”¶æ–‡ä»¶ {transfer['filename']}: {progress}", end="")

        # Check if file is complete
        if transfer["received_chunks"] == transfer["total_chunks"]:
            await self._complete_file_transfer(file_id)
            return True
            
        return False

    async def _complete_file_transfer(self, file_id: str):
        """å®Œæˆæ–‡ä»¶ä¼ è¾“"""
        transfer = self.pending_transfers[file_id]
        
        # Combine all chunks
        complete_data = b"".join(
            transfer["chunks"][i] 
            for i in range(transfer["total_chunks"])
        )

        # Save file
        save_path = self.temp_dir / transfer["filename"]
        try:
            with open(save_path, 'wb') as f:
                f.write(complete_data)
            print(f"\nâœ… æ–‡ä»¶ä¿å­˜åˆ°: {save_path}")
            
            # Add to cache
            file_hash = hashlib.md5(complete_data).hexdigest()
            self.add_to_file_cache(file_hash, str(save_path))
            
            # Add to clipboard on Mac
            if IS_MACOS:
                pasteboard = AppKit.NSPasteboard.generalPasteboard()
                pasteboard.clearContents()
                url = AppKit.NSURL.fileURLWithPath_(str(save_path))
                urls = AppKit.NSArray.arrayWithObject_(url)
                success = pasteboard.writeObjects_(urls)
                if success:
                    print(f"ğŸ“ å·²å°†æ–‡ä»¶æ·»åŠ åˆ°Macå‰ªè´´æ¿: {transfer['filename']}")
                else:
                    print("âŒ æ·»åŠ æ–‡ä»¶åˆ°å‰ªè´´æ¿å¤±è´¥")
            
        except Exception as e:
            print(f"\nâŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            
        # Cleanup
        del self.pending_transfers[file_id]

    def _format_progress(self, current: int, total: int) -> str:
        """æ ¼å¼åŒ–è¿›åº¦æ˜¾ç¤º"""
        percentage = (current * 100) // total
        bar_length = 20
        filled = (percentage * bar_length) // 100
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        return f"[{bar}] {percentage}% ({current}/{total})"

    def handle_received_chunk(self, message: dict) -> bool:
        """å¤„ç†æ¥æ”¶åˆ°çš„æ–‡ä»¶å—"""
        try:
            filename = message.get("filename", "unknown")
            chunk_index = message.get("chunk_index", 0)
            total_chunks = message.get("total_chunks", 1)
            chunk_data = base64.b64decode(message.get("chunk_data", ""))
            chunk_hash = message.get("chunk_hash")
            
            if not chunk_data:
                return False
                
            # éªŒè¯å—çš„å®Œæ•´æ€§
            if chunk_hash and hashlib.md5(chunk_data).hexdigest() != chunk_hash:
                print(f"âš ï¸ å— {chunk_index} æ ¡éªŒå¤±è´¥")
                return False
                
            save_path = self.temp_dir / filename
            
            # ä½¿ç”¨ msvcrt åœ¨ Windows ä¸Šè¿›è¡Œæ–‡ä»¶é”å®šï¼Œæˆ–åœ¨ Unix ä¸Šä½¿ç”¨ fcntl
            if IS_WINDOWS:
                import msvcrt
                with open(save_path, "ab") as f:
                    try:
                        # é”å®šæ–‡ä»¶ï¼Œä½¿ç”¨self.chunk_size
                        msvcrt.locking(f.fileno(), msvcrt.LK_NBLCK, self.chunk_size)
                        f.seek(chunk_index * self.chunk_size)  # ä½¿ç”¨ç›¸åŒçš„chunk_size
                        f.write(chunk_data)
                    finally:
                        # è§£é”æ–‡ä»¶
                        try:
                            msvcrt.locking(f.fileno(), msvcrt.LK_UNLCK, self.chunk_size)
                        except:
                            pass  # Ignore unlock errors
            else:
                # Unix/Mac ç³»ç»Ÿä½¿ç”¨ fcntl
                import fcntl
                with open(save_path, "ab") as f:
                    fcntl.flock(f.fileno(), fcntl.LOCK_EX)
                    try:
                        f.seek(chunk_index * self.chunk_size)  # ä½¿ç”¨ç›¸åŒçš„chunk_size
                        f.write(chunk_data)
                    finally:
                        fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                
            # æ›´æ–°ä¼ è¾“çŠ¶æ€
            if filename not in self.file_transfers:
                self.file_transfers[filename] = {
                    "received_chunks": set([chunk_index]),
                    "total_chunks": total_chunks,
                    "path": save_path
                }
            else:
                self.file_transfers[filename]["received_chunks"].add(chunk_index)
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            transfer = self.file_transfers[filename]
            is_complete = len(transfer["received_chunks"]) == transfer["total_chunks"]
            
            if is_complete:
                # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
                if self._verify_file_integrity(save_path):
                    return True
                else:
                    print(f"âš ï¸ æ–‡ä»¶ {filename} å®Œæ•´æ€§éªŒè¯å¤±è´¥")
                    return False
                    
            return False
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _verify_file_integrity(self, file_path: Path) -> bool:
        """éªŒè¯æ–‡ä»¶çš„å®Œæ•´æ€§"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
                
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = file_path.stat().st_size
            if file_size == 0:
                print(f"âŒ æ–‡ä»¶ä¸ºç©º: {file_path}")
                return False
                
            # å°è¯•è¯»å–æ–‡ä»¶
            try:
                with open(file_path, 'rb') as f:
                    # è¯»å–ç¬¬ä¸€ä¸ªå—æ¥éªŒè¯æ–‡ä»¶å¯è®¿é—®æ€§
                    first_chunk = f.read(8192)  # 8KB
                    if first_chunk is None:
                        print(f"âŒ æ–‡ä»¶æ— æ³•è¯»å–: {file_path}")
                        return False
            except Exception as e:
                print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                return False
                
            print(f"âœ… æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡: {file_path.name}")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    # æ–‡ä»¶ç¼“å­˜ç›¸å…³æ–¹æ³•
    def load_file_cache(self):
        """åŠ è½½æ–‡ä»¶ç¼“å­˜"""
        cache_path = self.temp_dir / "filecache.json"
        try:
            if cache_path.exists():
                with open(cache_path, "r") as f:
                    self.file_cache = json.load(f)
                print(f"ğŸ“š å·²åŠ è½½ {len(self.file_cache)} ä¸ªæ–‡ä»¶ç¼“å­˜æ¡ç›®")
            else:
                self.file_cache = {}
                print("ğŸ“ åˆ›å»ºæ–°çš„æ–‡ä»¶ç¼“å­˜")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            self.file_cache = {}

    def save_file_cache(self):
        """ä¿å­˜æ–‡ä»¶ç¼“å­˜ä¿¡æ¯"""
        cache_path = self.temp_dir / "filecache.json"
        try:
            with open(cache_path, "w") as f:
                json.dump(self.file_cache, f)
        except:
            print("âŒ ä¿å­˜æ–‡ä»¶ç¼“å­˜å¤±è´¥")

    def add_to_file_cache(self, file_hash, file_path):
        """æ·»åŠ æ–‡ä»¶åˆ°ç¼“å­˜"""
        if Path(file_path).exists():
            self.file_cache[file_hash] = str(file_path)
            self.save_file_cache()

    def get_from_file_cache(self, file_hash):
        """ä»ç¼“å­˜è·å–æ–‡ä»¶è·¯å¾„"""
        path = self.file_cache.get(file_hash)
        if path and Path(path).exists():
            return path
        return None

    async def handle_received_files(self, message, sender_websocket, broadcast_fn):
        """å¤„ç†æ”¶åˆ°çš„æ–‡ä»¶ä¿¡æ¯"""
        files = message["files"]
        if not files:
            print("âŒ æ”¶åˆ°ç©ºçš„æ–‡ä»¶åˆ—è¡¨")
            return False

        file_paths = [f["path"] for f in files if "path" in f]
        content_hashes = [self._get_files_content_hash([p]) for p in file_paths]
        for h in content_hashes:
            if h and h in self.file_cache:
                print("â­ï¸ è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶å†…å®¹ï¼Œä¸å†è¯·æ±‚")
                return h
        # ...åç»­è¯·æ±‚æ–‡ä»¶å†…å®¹...
        
        file_names = [f["filename"] for f in files]
        print(f"ğŸ“¥ æ”¶åˆ°æ–‡ä»¶ä¿¡æ¯: {', '.join(file_names[:3])}{' ç­‰' if len(file_names) > 3 else ''}")

        # è®¡ç®—æ–‡ä»¶ä¿¡æ¯çš„å“ˆå¸Œå€¼
        file_info_hash = hashlib.md5(str(files).encode()).hexdigest()

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for file_info in files:
            file_path = file_info.get("path", "")
            if not file_path:
                print("âš ï¸ æ”¶åˆ°çš„æ–‡ä»¶ä¿¡æ¯ä¸­ç¼ºå°‘è·¯å¾„")
                continue

            filename = file_info.get("filename", os.path.basename(file_path))
            print(f"ğŸ“¥ å‡†å¤‡ä¸‹è½½æ–‡ä»¶: {filename}")

            # åˆ›å»ºæ–‡ä»¶è¯·æ±‚æ¶ˆæ¯
            file_req = ClipMessage.file_request_message(file_path)
            req_json = ClipMessage.serialize(file_req)
            encrypted_req = self.security_mgr.encrypt_message(req_json.encode('utf-8'))

            if sender_websocket:
                await sender_websocket.send(encrypted_req)
                print(f"ğŸ“¤ å‘æºè®¾å¤‡è¯·æ±‚æ–‡ä»¶: {filename}")
            else:
                await broadcast_fn(encrypted_req)
                print(f"ğŸ“¤ å¹¿æ’­æ–‡ä»¶è¯·æ±‚: {filename}")

        return file_info_hash

    def set_clipboard_file(self, file_path):
        """å°†æ–‡ä»¶è·¯å¾„è®¾ç½®åˆ°å‰ªè´´æ¿"""
        try:
            path_str = str(file_path)
            if IS_MACOS:
                pasteboard = AppKit.NSPasteboard.generalPasteboard()
                pasteboard.clearContents()
                url = AppKit.NSURL.fileURLWithPath_(path_str)
                urls = AppKit.NSArray.arrayWithObject_(url)
                success = pasteboard.writeObjects_(urls)
                if success:
                    print(f"ğŸ“ å·²å°†æ–‡ä»¶æ·»åŠ åˆ°Macå‰ªè´´æ¿: {os.path.basename(path_str)}")
                    return pasteboard.changeCount()
                else:
                    print("âŒ æ·»åŠ æ–‡ä»¶åˆ°å‰ªè´´æ¿å¤±è´¥")
                    return None
            elif IS_WINDOWS:
                import win32clipboard
                import win32con
                try:
                    win32clipboard.OpenClipboard()
                    win32clipboard.EmptyClipboard()
                    # Use CF_HDROP for proper file handling
                    win32clipboard.SetClipboardData(win32con.CF_HDROP, tuple([path_str]))
                    win32clipboard.CloseClipboard()
                    print(f"ğŸ“ å·²å°†æ–‡ä»¶æ·»åŠ åˆ°Windowså‰ªè´´æ¿: {os.path.basename(path_str)}")
                    return True
                except Exception as e:
                    print(f"âŒ Windowså‰ªè´´æ¿æ“ä½œå¤±è´¥: {e}")
                    return None
        except Exception as e:
            print(f"âŒ è®¾ç½®å‰ªè´´æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return None

    async def handle_clipboard_files(self, file_urls, last_content_hash, broadcast_fn):
        """å¤„ç†å‰ªè´´æ¿ä¸­çš„æ–‡ä»¶"""
        # è®¡ç®—æ–‡ä»¶è·¯å¾„å“ˆå¸Œ
        file_str = str(file_urls)
        content_hash = hashlib.md5(file_str.encode()).hexdigest()
        
        # æ£€æŸ¥é‡å¤
        if content_hash == last_content_hash:
            print("â­ï¸ è·³è¿‡é‡å¤æ–‡ä»¶è·¯å¾„")
            return content_hash
            
        # æ˜¾ç¤ºå‘é€çš„æ–‡ä»¶è·¯å¾„
        file_names = [os.path.basename(p) for p in file_urls]
        print(f"ğŸ“¤ å‘é€æ–‡ä»¶: {', '.join(file_names[:3])}{' ç­‰' if len(file_names) > 3 else ''}")
        
        # åˆ›å»ºå¹¶å‘é€æ–‡ä»¶æ¶ˆæ¯
        file_msg = ClipMessage.file_message(file_urls)
        message_json = ClipMessage.serialize(file_msg)
        encrypted_data = self.security_mgr.encrypt_message(message_json.encode('utf-8'))
        print("ğŸ” åŠ å¯†åçš„æ–‡ä»¶æ¶ˆæ¯")
        await broadcast_fn(encrypted_data)

        # å¤„ç†æ–‡ä»¶ä¼ è¾“
        print("ğŸ”„ å‡†å¤‡ä¸»åŠ¨ä¼ è¾“æ–‡ä»¶å†…å®¹...")
        for file_path in file_urls:
            await self.handle_file_transfer(file_path, broadcast_fn)
            
        return content_hash

    async def process_clipboard_content(self, text: str, current_time: float, last_content_hash: str, 
                                     last_update_time: float, broadcast_fn) -> tuple:
        """å¤„ç†å‰ªè´´æ¿æ–‡æœ¬å†…å®¹"""
        # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œä¸å¤„ç†
        if not text or text.strip() == "":
            return last_content_hash, last_update_time
        
        # å¦‚æœçœ‹èµ·æ¥åƒä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼Œè·³è¿‡
        if self._looks_like_temp_file_path(text):
            return last_content_hash, last_update_time
        
        # è®¡ç®—å†…å®¹å“ˆå¸Œï¼Œç”¨äºé˜²æ­¢é‡å¤å‘é€
        content_hash = hashlib.md5(text.encode()).hexdigest()
        
        # å¦‚æœå’Œä¸Šæ¬¡æ¥æ”¶/å‘é€çš„å†…å®¹ç›¸åŒï¼Œåˆ™è·³è¿‡
        if content_hash == last_content_hash:
            print(f"â­ï¸ è·³è¿‡é‡å¤å†…å®¹: å“ˆå¸Œå€¼ {content_hash[:8]}... ç›¸åŒ")
            return last_content_hash, last_update_time
        
        # æ·»åŠ å»¶è¿Ÿæ£€æŸ¥ - å¦‚æœè·ç¦»ä¸Šæ¬¡æ›´æ–°å‰ªè´´æ¿æ—¶é—´å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯æˆ‘ä»¬è‡ªå·±åˆšåˆšæ›´æ–°çš„
        if current_time - last_update_time < 1.0:  # å¢åŠ å»¶è¿Ÿé˜ˆå€¼
            print(f"â±ï¸ å»¶è¿Ÿæ£€æŸ¥: è·ç¦»ä¸Šæ¬¡æ›´æ–°æ—¶é—´ {current_time - last_update_time:.2f}ç§’ï¼Œå¯èƒ½æ˜¯è‡ªå·±æ›´æ–°çš„å†…å®¹")
            return last_content_hash, last_update_time
        
        # æ˜¾ç¤ºå‘é€çš„å†…å®¹ï¼ˆé™åˆ¶å­—ç¬¦æ•°ï¼‰
        max_display_len = 100
        display_content = text if len(text) <= max_display_len else text[:max_display_len] + "..."
        print(f"ğŸ“¤ å‘é€æ–‡æœ¬: \"{display_content}\"")
        
        # åˆ›å»ºæ–‡æœ¬æ¶ˆæ¯
        text_msg = ClipMessage.text_message(text)
        message_json = ClipMessage.serialize(text_msg)
        
        # åŠ å¯†å¹¶å¹¿æ’­
        encrypted_data = self.security_mgr.encrypt_message(message_json.encode('utf-8'))
        print("ğŸ” åŠ å¯†åçš„æ–‡æœ¬")
        
        # æ›´æ–°çŠ¶æ€
        new_update_time = time.time()
        
        # å‘é€åŠ å¯†æ•°æ®
        await broadcast_fn(encrypted_data)
        
        return content_hash, new_update_time

    def _looks_like_temp_file_path(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦çœ‹èµ·æ¥åƒä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        temp_indicators = [
            "\\AppData\\Local\\Temp\\clipshare_files\\",
            "/var/folders/",
            "/tmp/clipshare_files/",
            "C:\\Users\\\\AppData\\Local\\Temp\\clipshare_files\\"
        ]
        
        for indicator in temp_indicators:
            if indicator in text:
                print(f"â­ï¸ è·³è¿‡ä¸´æ—¶æ–‡ä»¶è·¯å¾„: \"{text[:40]}...\"")
                return True
        return False