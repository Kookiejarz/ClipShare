from pathlib import Path
import hashlib
import json
import base64
import asyncio
import os
import time
from utils.platform_config import IS_MACOS, IS_WINDOWS
from utils.message_format import ClipMessage, MessageType
from config import ClipboardConfig

# Only import AppKit and objc on macOS
if IS_MACOS:
    import AppKit
    import objc # Import objc

    # Helper class to perform pasteboard operations on the main thread
    class PasteboardSetter(AppKit.NSObject):
        @classmethod # Use standard Python classmethod decorator
        def setFileURL_(cls, path_str):
            try:
                pasteboard = AppKit.NSPasteboard.generalPasteboard()
                pasteboard.clearContents()
                url = AppKit.NSURL.fileURLWithPath_(path_str)
                if not url:
                    print(f"âŒ [MainThread] æ— æ³•åˆ›å»ºæ–‡ä»¶URL: {path_str}")
                    return "0|-1"
                urls = AppKit.NSArray.arrayWithObject_(url)
                success = pasteboard.writeObjects_(urls)
                if success:
                    change_count = pasteboard.changeCount()
                    print(f"ğŸ“ [MainThread] å·²å°†æ–‡ä»¶æ·»åŠ åˆ°Macå‰ªè´´æ¿: {Path(path_str).name}")
                    return f"1|{change_count}"
                else:
                    print(f"âŒ [MainThread] æ·»åŠ æ–‡ä»¶åˆ°Macå‰ªè´´æ¿å¤±è´¥: {Path(path_str).name}")
                    return "0|-1"
            except Exception as e:
                print(f"âŒ [MainThread] è®¾ç½®å‰ªè´´æ¿æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                return "0|-1"


class FileHandler:
    """æ–‡ä»¶å¤„ç†ç®¡ç†å™¨"""
    
    def __init__(self, temp_dir: Path, security_mgr):
        self.temp_dir = temp_dir
        self.security_mgr = security_mgr
        self.file_transfers = {}
        self.file_cache = {}
        self._init_temp_dir()
        self.load_file_cache()
        self.chunk_size = ClipboardConfig.CHUNK_SIZE # Use config
        self.pending_transfers = {}  # Track ongoing chunked transfers

    def _init_temp_dir(self):
        """åˆå§‹åŒ–ä¸´æ—¶ç›®å½•"""
        self.temp_dir.mkdir(exist_ok=True)
        print(f"âœ… æ–‡ä»¶å¤„ç†åˆå§‹åŒ–æˆåŠŸï¼Œä¸´æ—¶ç›®å½•: {self.temp_dir}")

    def _looks_like_temp_file_path(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦çœ‹èµ·æ¥åƒä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        for indicator in ClipboardConfig.TEMP_PATH_INDICATORS:
            if indicator in text:
                print(f"â­ï¸ è·³è¿‡ä¸´æ—¶æ–‡ä»¶è·¯å¾„: \"{text[:40]}...\"")
                return True
        return False

    async def handle_file_transfer(self, file_path: str, send_encrypted_fn):
        """å¤„ç†æ–‡ä»¶ä¼ è¾“ï¼ˆè‡ªåŠ¨åˆ†å—å¤§æ–‡ä»¶ï¼‰"""
        path_obj = Path(file_path)
        MAX_CHUNK_SIZE = self.chunk_size # Use instance chunk size

        if not path_obj.exists() or not path_obj.is_file():
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ•ˆ: {file_path}")
            return False

        try:
            file_size = path_obj.stat().st_size
            total_chunks = (file_size + MAX_CHUNK_SIZE - 1) // MAX_CHUNK_SIZE
            print(f"ğŸ“¤ å¼€å§‹ä¼ è¾“æ–‡ä»¶: {path_obj.name} ({file_size/1024/1024:.1f}MB, {total_chunks}å—)")

            # å‘é€æ–‡ä»¶å¼€å§‹æ¶ˆæ¯ (optional, could be part of the first chunk)
            # Consider if a separate start message is needed or if info can be in first chunk

            # é€å—è¯»å–å¹¶å‘é€æ–‡ä»¶
            with open(path_obj, 'rb') as f:
                for chunk_index in range(total_chunks):
                    chunk_data = f.read(MAX_CHUNK_SIZE)
                    if not chunk_data:
                        break

                    chunk_msg = {
                        'type': MessageType.FILE_RESPONSE,
                        'filename': path_obj.name,
                        'exists': True,
                        'chunk_data': base64.b64encode(chunk_data).decode('utf-8'),
                        'chunk_index': chunk_index,
                        'total_chunks': total_chunks,
                        'chunk_hash': hashlib.md5(chunk_data).hexdigest(),
                        'file_hash': ClipMessage.calculate_file_hash(str(path_obj)) if chunk_index == 0 else None # Send full hash only once
                    }

                    # æ˜¾ç¤ºè¿›åº¦
                    progress = self._format_progress(chunk_index + 1, total_chunks)
                    print(f"\rğŸ“¤ ä¼ è¾“æ–‡ä»¶ {path_obj.name}: {progress}", end="", flush=True)

                    # åŠ å¯†å¹¶å‘é€å—
                    await send_encrypted_fn(json.dumps(chunk_msg).encode('utf-8'))
                    await asyncio.sleep(ClipboardConfig.NETWORK_DELAY) # Use config

            print(f"\nâœ… æ–‡ä»¶ {path_obj.name} ä¼ è¾“å®Œæˆ")
            return True

        except Exception as e:
            print(f"\nâŒ æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    # Removed _transfer_small_file as handle_file_transfer now handles chunking

    # Removed send_large_file and _send_file_chunk as handle_file_transfer covers this

    # Removed receive_file_chunk as handle_received_chunk covers this

    # Removed _complete_file_transfer as handle_received_chunk handles completion

    def _format_progress(self, current: int, total: int) -> str:
        """æ ¼å¼åŒ–è¿›åº¦æ˜¾ç¤º"""
        if total <= 0: return "[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0% (0/0)" # Avoid division by zero
        percentage = (current * 100) // total
        bar_length = 20
        filled = min(bar_length, (percentage * bar_length) // 100) # Ensure filled doesn't exceed bar_length
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        return f"[{bar}] {percentage}% ({current}/{total})"

    def handle_received_chunk(self, message: dict) -> tuple[bool, Path | None]:
        """
        å¤„ç†æ¥æ”¶åˆ°çš„æ–‡ä»¶å—.
        Returns: (is_complete, file_path_if_complete)
        """
        try:
            filename = message.get("filename", "unknown")
            chunk_index = message.get("chunk_index", 0)
            total_chunks = message.get("total_chunks", 1)
            chunk_data = base64.b64decode(message.get("chunk_data", ""))
            chunk_hash = message.get("chunk_hash")
            file_hash = message.get("file_hash") # Full file hash (sent with first chunk)

            if not chunk_data:
                print("âš ï¸ æ”¶åˆ°çš„æ–‡ä»¶å—æ•°æ®ä¸ºç©º")
                return False, None

            # éªŒè¯å—çš„å®Œæ•´æ€§
            if chunk_hash and hashlib.md5(chunk_data).hexdigest() != chunk_hash:
                print(f"âš ï¸ å— {chunk_index+1}/{total_chunks} æ ¡éªŒå¤±è´¥ for {filename}")
                # Optionally request retransmission here
                return False, None

            save_path = self.temp_dir / filename

            # Initialize transfer state if first chunk
            if filename not in self.file_transfers:
                self.file_transfers[filename] = {
                    "received_chunks": {}, # Store data by index
                    "total_chunks": total_chunks,
                    "path": save_path,
                    "file_hash": file_hash # Store the expected full hash
                }
                # Clear any old file with the same name
                if save_path.exists():
                    try:
                        save_path.unlink()
                    except OSError as e:
                        print(f"âš ï¸ æ— æ³•åˆ é™¤æ—§æ–‡ä»¶ {save_path}: {e}")


            transfer = self.file_transfers[filename]

            # Store chunk data if not already received
            if chunk_index not in transfer["received_chunks"]:
                 transfer["received_chunks"][chunk_index] = chunk_data
            else:
                 print(f"â„¹ï¸ æ”¶åˆ°é‡å¤å— {chunk_index+1}/{total_chunks} for {filename}")


            # Display progress
            progress = self._format_progress(len(transfer["received_chunks"]), transfer["total_chunks"])
            print(f"\rğŸ“¥ æ¥æ”¶æ–‡ä»¶ {filename}: {progress}", end="", flush=True)


            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            is_complete = len(transfer["received_chunks"]) == transfer["total_chunks"]

            if is_complete:
                print(f"\nâœ… æ–‡ä»¶ {filename} æ‰€æœ‰å—æ¥æ”¶å®Œæˆï¼Œå¼€å§‹ç»„è£…...")
                # ç»„è£…æ–‡ä»¶
                try:
                    with open(save_path, "wb") as f:
                        for i in range(transfer["total_chunks"]):
                            if i in transfer["received_chunks"]:
                                f.write(transfer["received_chunks"][i])
                            else:
                                # This shouldn't happen if is_complete is true, but as a safeguard
                                print(f"âŒ ç»„è£…æ–‡ä»¶ {filename} æ—¶ç¼ºå°‘å— {i+1}")
                                raise IOError(f"Missing chunk {i+1} for {filename}")

                    # éªŒè¯å®Œæ•´æ–‡ä»¶å“ˆå¸Œ
                    if transfer["file_hash"]:
                        actual_hash = ClipMessage.calculate_file_hash(str(save_path))
                        if actual_hash == transfer["file_hash"]:
                            print(f"âœ… æ–‡ä»¶ {filename} å“ˆå¸Œæ ¡éªŒæˆåŠŸ")
                        else:
                            print(f"âŒ æ–‡ä»¶ {filename} å“ˆå¸Œæ ¡éªŒå¤±è´¥! Expected: {transfer['file_hash']}, Got: {actual_hash}")
                            # Optionally delete the corrupted file
                            # save_path.unlink()
                            del self.file_transfers[filename]
                            return False, None # Indicate failure
                    else:
                         print(f"âš ï¸ æœªæ”¶åˆ°æ–‡ä»¶ {filename} çš„å®Œæ•´å“ˆå¸Œå€¼ï¼Œè·³è¿‡æ ¡éªŒ")


                    # Add to cache (using the verified hash if available)
                    final_hash = transfer["file_hash"] or ClipMessage.calculate_file_hash(str(save_path))
                    self.add_to_file_cache(final_hash, str(save_path))

                    # æ¸…ç†ä¼ è¾“çŠ¶æ€
                    completed_path = transfer["path"]
                    del self.file_transfers[filename]
                    return True, completed_path # Indicate completion and return path

                except Exception as e:
                    print(f"âŒ ç»„è£…æˆ–æ ¡éªŒæ–‡ä»¶ {filename} å¤±è´¥: {e}")
                    # Clean up
                    if save_path.exists(): save_path.unlink(missing_ok=True)
                    if filename in self.file_transfers: del self.file_transfers[filename]
                    return False, None # Indicate failure

            return False, None # Indicate not yet complete

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, None # Indicate failure

    # Removed _verify_file_integrity as validation is now part of handle_received_chunk

    # --- File Cache Methods ---
    def load_file_cache(self):
        """åŠ è½½æ–‡ä»¶ç¼“å­˜"""
        cache_path = self.temp_dir / "filecache.json"
        try:
            if cache_path.exists():
                with open(cache_path, "r") as f:
                    self.file_cache = json.load(f)
                print(f"ğŸ“š å·²åŠ è½½ {len(self.file_cache)} ä¸ªæ–‡ä»¶ç¼“å­˜æ¡ç›®")
            else:
                self.file_cache = {}
                print("ğŸ“ åˆ›å»ºæ–°çš„æ–‡ä»¶ç¼“å­˜")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            self.file_cache = {}

    def save_file_cache(self):
        """ä¿å­˜æ–‡ä»¶ç¼“å­˜ä¿¡æ¯"""
        cache_path = self.temp_dir / "filecache.json"
        try:
            with open(cache_path, "w") as f:
                json.dump(self.file_cache, f)
        except Exception as e: # Catch specific exceptions if needed
            print(f"âŒ ä¿å­˜æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")

    def add_to_file_cache(self, file_hash, file_path):
        """æ·»åŠ æ–‡ä»¶åˆ°ç¼“å­˜"""
        if Path(file_path).exists():
            self.file_cache[file_hash] = str(file_path)
            self.save_file_cache()

    def get_from_file_cache(self, file_hash):
        """ä»ç¼“å­˜è·å–æ–‡ä»¶è·¯å¾„"""
        path = self.file_cache.get(file_hash)
        if path:
            path_obj = Path(path)
            if path_obj.exists():
                return str(path_obj)
            else:
                # Remove stale entry from cache
                print(f"ğŸ§¹ æ¸…ç†æ— æ•ˆç¼“å­˜æ¡ç›®: {file_hash} -> {path}")
                del self.file_cache[file_hash]
                self.save_file_cache()
        return None

    def get_files_content_hash(self, file_paths):
        """è®¡ç®—å¤šä¸ªæ–‡ä»¶å†…å®¹çš„MD5å“ˆå¸Œå€¼ï¼Œè·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶"""
        # This is now an instance method, no need for @staticmethod
        md5 = hashlib.md5()
        valid_paths_found = False
        for path_str in file_paths:
            path = Path(path_str) # Ensure it's a Path object
            try:
                if not path.is_file(): # Check if it's a file
                    print(f"âš ï¸ è·³è¿‡éæ–‡ä»¶æˆ–ä¸å­˜åœ¨çš„è·¯å¾„: {path}")
                    continue

                with open(path, 'rb') as f:
                    valid_paths_found = True
                    while True:
                        # Read in larger chunks for potentially better performance
                        chunk = f.read(1024 * 1024) # 1MB chunks
                        if not chunk:
                            break
                        md5.update(chunk)
            except FileNotFoundError:
                print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å“ˆå¸Œ: {path}")
                continue
            except PermissionError:
                 print(f"âš ï¸ æƒé™ä¸è¶³ï¼Œæ— æ³•è¯»å–æ–‡ä»¶: {path}")
                 continue
            except Exception as e:
                print(f"âŒ è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {path} - {e}")
                # Depending on desired behavior, you might want to return None here
                # or just skip the problematic file. Skipping for now.
                continue
        # Only return a hash if at least one valid file was processed
        return md5.hexdigest() if valid_paths_found else None

    async def handle_received_files(self, file_info_message, send_encrypted_func, sender_websocket=None):
        """
        Handles a received FILE message containing file metadata.
        Checks the cache and requests missing files from the sender.
        """
        files = file_info_message.get("files", [])
        if not files:
            print("âŒ æ”¶åˆ°ç©ºçš„æ–‡ä»¶åˆ—è¡¨")
            return False

        files_to_request = []
        file_names = []

        for file_info in files:
            file_hash = file_info.get("hash")
            filename = file_info.get("filename")
            file_path = file_info.get("path") # Original path from sender

            if not filename or not file_path:
                 print("âš ï¸ æ”¶åˆ°çš„æ–‡ä»¶ä¿¡æ¯ç¼ºå°‘åç§°æˆ–è·¯å¾„")
                 continue

            file_names.append(filename)

            # Check cache first
            if file_hash and self.get_from_file_cache(file_hash):
                print(f"âœ… æ–‡ä»¶ '{filename}' åœ¨ç¼“å­˜ä¸­æ‰¾åˆ° (Hash: {file_hash[:8]}...)")
                # Optionally: Update clipboard here if only one file and it's cached?
                # For now, we just skip the request.
                continue
            else:
                if file_hash:
                    print(f"â„¹ï¸ æ–‡ä»¶ '{filename}' ä¸åœ¨ç¼“å­˜ä¸­æˆ–å“ˆå¸Œç¼ºå¤±ï¼Œè¯·æ±‚ä¼ è¾“ã€‚")
                files_to_request.append(file_path) # Use original path for request

        if not files_to_request:
            print("âœ… æ‰€æœ‰æ”¶åˆ°çš„æ–‡ä»¶éƒ½åœ¨ç¼“å­˜ä¸­ï¼Œæ— éœ€è¯·æ±‚ã€‚")
            # If all files are cached, potentially update clipboard now?
            # Needs careful consideration if multiple files were sent.
            return True # Indicate success (all cached or no files)

        print(f"ğŸ“¥ æ”¶åˆ°æ–‡ä»¶ä¿¡æ¯: {', '.join(file_names[:3])}{' ç­‰' if len(file_names) > 3 else ''}")
        print(f"ğŸ“¤ è¯·æ±‚ {len(files_to_request)} ä¸ªæ–‡ä»¶å†…å®¹...")

        # Request each missing file
        for file_path in files_to_request:
            filename = Path(file_path).name # Extract filename for logging
            print(f"ğŸ“¤ è¯·æ±‚æ–‡ä»¶: {filename}")
            file_req = ClipMessage.file_request_message(file_path) # Request using original path
            req_json = ClipMessage.serialize(file_req)

            # Encrypt and send the request
            # If sender_websocket is provided, send directly, otherwise broadcast
            try:
                await send_encrypted_func(req_json.encode('utf-8'))
            except Exception as e:
                print(f"âŒ å‘é€æ–‡ä»¶è¯·æ±‚å¤±è´¥ ({Path(file_path).name}): {e}")
                # Consider how to handle partial request failures

            await asyncio.sleep(ClipboardConfig.NETWORK_DELAY) # Small delay between requests

        return True # Indicate requests were sent

    async def set_clipboard_file(self, file_path: Path):
        """å°†æ–‡ä»¶è·¯å¾„è®¾ç½®åˆ°å‰ªè´´æ¿ (Uses main thread for macOS)"""
        try:
            path_str = str(file_path)
            if IS_MACOS:
                objc.registerMetaDataForSelector(
                    b'PasteboardSetter', b'setFileURL_', {'retval': {'type': b'@'}}
                )
                # Use executor to run the blocking operation in a separate thread
                import asyncio
                import concurrent.futures
                
                loop = asyncio.get_event_loop()
                def blocking_clipboard_operation():
                    return PasteboardSetter.performSelectorOnMainThread_withObject_waitUntilDone_(
                        'setFileURL:', path_str, True
                    )
                
                # Run in thread pool to avoid blocking the async event loop
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    result = await loop.run_in_executor(executor, blocking_clipboard_operation)
                
                if result is None:
                    # print("âš ï¸ ä¸»çº¿ç¨‹å‰ªè´´æ¿æ“ä½œæœªè¿”å›ç»“æœï¼Œå¯èƒ½æœªæ­£ç¡®æ³¨å†Œ PasteboardSetter æˆ–æ–¹æ³•æœªè¢«è°ƒç”¨ã€‚")
                    return None
                # è§£æ result
                try:
                    success_str, change_count_str = result.split("|")
                    success = success_str == "1"
                    change_count = int(change_count_str)
                except Exception as e:
                    print(f"âš ï¸ è§£æä¸»çº¿ç¨‹è¿”å›å€¼å¤±è´¥: {result} ({e})")
                    return None
                if success:
                    return change_count
                else:
                    return None

            elif IS_WINDOWS:
                # Windows specific logic will be called from windows_client.py
                # This method primarily handles the macOS part or acts as a placeholder
                print(f"â„¹ï¸ Windowså‰ªè´´æ¿è®¾ç½®åº”åœ¨å®¢æˆ·ç«¯å¤„ç†: {file_path.name}")
                # We return True here to indicate the file handler part is done,
                # but the actual clipboard setting happens in windows_client.py
                return True
            else:
                print("âš ï¸ æœªçŸ¥çš„æ“ä½œç³»ç»Ÿï¼Œæ— æ³•è®¾ç½®å‰ªè´´æ¿æ–‡ä»¶")
                return None
        except Exception as e:
            print(f"âŒ è®¾ç½®å‰ªè´´æ¿æ–‡ä»¶æ—¶å‡ºé”™ (Outer): {e}")
            import traceback
            traceback.print_exc()
            return None


    async def handle_clipboard_files(self, file_urls, last_content_hash, send_encrypted_fn):
        """å¤„ç†å‰ªè´´æ¿ä¸­çš„æ–‡ä»¶, å‘é€æ–‡ä»¶ä¿¡æ¯"""
        # Calculate hash based on the list of file paths
        file_paths_str = str(sorted(file_urls)) # Sort for consistent hashing
        content_hash = hashlib.md5(file_paths_str.encode()).hexdigest()

        # Check for duplicates based on the list of paths
        if content_hash == last_content_hash:
            # print("â­ï¸ è·³è¿‡é‡å¤æ–‡ä»¶è·¯å¾„åˆ—è¡¨") # Less verbose logging
            return content_hash, False # Return hash, indicate no change sent

        # Display sending file paths
        file_names = [os.path.basename(p) for p in file_urls]
        print(f"ğŸ“¤ å‘é€æ–‡ä»¶ä¿¡æ¯: {', '.join(file_names[:3])}{' ç­‰' if len(file_names) > 3 else ''}")

        # Create file message (includes hashes now)
        file_msg = ClipMessage.file_message(file_urls)
        message_json = ClipMessage.serialize(file_msg)

        # Encrypt and broadcast file info
        await send_encrypted_fn(message_json.encode('utf-8'))
        print("ğŸ” å·²å‘é€åŠ å¯†çš„æ–‡ä»¶ä¿¡æ¯")

        # Return the new hash and indicate that a change was sent
        return content_hash, True


    async def process_clipboard_content(self, text: str, current_time: float, last_content_hash: str,
                                     last_update_time: float, send_encrypted_fn) -> tuple[str, float, bool]:
        """
        å¤„ç†å‰ªè´´æ¿æ–‡æœ¬å†…å®¹, å‘é€æ–‡æœ¬æ¶ˆæ¯.
        Returns: (new_hash, new_update_time, sent_update)
        """
        # If content is empty or looks like temp path, do nothing
        if not text or text.strip() == "" or self._looks_like_temp_file_path(text):
            return last_content_hash, last_update_time, False

        # Calculate content hash
        content_hash = hashlib.md5(text.encode()).hexdigest()

        # If same as last content, skip
        if content_hash == last_content_hash:
            # print(f"â­ï¸ è·³è¿‡é‡å¤æ–‡æœ¬å†…å®¹: å“ˆå¸Œå€¼ {content_hash[:8]}...") # Less verbose
            return last_content_hash, last_update_time, False

        # Anti-loop delay check (moved to client/server logic before calling this)
        # if current_time - last_update_time < ClipboardConfig.UPDATE_DELAY:
        #     print(f"â±ï¸ å»¶è¿Ÿæ£€æŸ¥: è·ç¦»ä¸Šæ¬¡æ›´æ–°æ—¶é—´ {current_time - last_update_time:.2f}ç§’ï¼Œå¯èƒ½æ˜¯è‡ªå·±æ›´æ–°çš„å†…å®¹")
        #     return last_content_hash, last_update_time, False

        # Display sending content (limited length)
        display_content = text[:ClipboardConfig.MAX_DISPLAY_LENGTH] + ("..." if len(text) > ClipboardConfig.MAX_DISPLAY_LENGTH else "")
        print(f"ğŸ“¤ å‘é€æ–‡æœ¬: \"{display_content}\"")

        # Create text message
        text_msg = ClipMessage.text_message(text)
        message_json = ClipMessage.serialize(text_msg)

        # Encrypt and broadcast
        await send_encrypted_fn(message_json.encode('utf-8'))
        print("ğŸ” å·²å‘é€åŠ å¯†çš„æ–‡æœ¬")

        # Return new state
        new_update_time = time.time()
        return content_hash, new_update_time, True